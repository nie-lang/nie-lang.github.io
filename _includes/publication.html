<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
*//*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 400px;
			height: 230px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 50px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 17.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 800px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			padding-bottom: 0px;
			min-height: 150px;

		}
		.paperTitle{
			font-size:14.0pt;
			mso-bidi-font-size:18.0pt;
			font-family:Times;
			mso-bidi-font-family:Times;
			margin-top: 10px;
			margin-bottom: 10px;
			font-weight: bold;
		}
		.paperName,.paperPub{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    line-height:150%;
		}
		.link{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 10px;
		    margin-bottom: 0px;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 1200;

		}
		.short div.sub-left, .short div.sub-right{
			height:160px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>


<h3>
	<a name='publications'></a> Selected Publications
</h3>

<h4>
	<a name='pre'></a> <b>Preprint</b>
</h4>		
<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ropstitch.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Robust Image Stitching with Optimal Plane</strong><br />
					   <strong>Lang Nie*</strong>, Yuan Mei*, Kang Liao, Yunqiu Xu, Chunyu Lin, Bin Xiao (* Equal contribution)<br />
					   <a href="https://arxiv.org/abs/2508.05903">[Paper]</a>
					  <a href="https://github.com/MmelodYy/RopStitch">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/MmelodYy/RopStitch?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>		
<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Calib_Survey.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Deep Learning for Camera Calibration and Beyond: A Survey</strong><br />
					   Kang Liao, <strong>Lang Nie</strong>, Shujuan Huang, Chunyu Lin, Jing Zhang, Yao Zhao, Moncef Gabbouj, Dacheng Tao<br />
					   <a href="https://arxiv.org/abs/2303.10559">[Paper]</a>
					   <a href="https://github.com/KangLiao929/Awesome-Deep-Camera-Calibration">[Project Page]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/KangLiao929/Awesome-Deep-Camera-Calibration?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/PanoGabor.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Revisiting 360 Depth Estimation with PanoGabor: A New Fusion Perspective</strong><br />
					   Zhijie Shen, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Weisi Lin, Yao Zhao<br />
					   <a href="https://arxiv.org/abs/2408.16227">[Paper]</a>
					   <a href="https://github.com/zhijieshen-bjtu/PGFuse">[Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/FE2E.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>From Editor to Dense Geometry Estimator</strong><br />
						Jiyuan Wang, Chunyu Lin, Lei Sun, Rongying Liu, <strong>Lang Nie</strong>, Mingxing Li, Kang Liao, Xiangxiang Chu, Yao Zhao<br />
						<a href="https://amap-ml.github.io/FE2E/">[Project Page]</a>
					   <a href="https://arxiv.org/abs/2509.04338">[Paper]</a>
					   <a href="https://github.com/AMAP-ML/FE2E">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/AMAP-ML/FE2E?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/VideoPD.gif" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Beyond Wide-Angle Images: Structure-to-Detail Video Portrait Correction via Unsupervised Spatiotemporal Adaptation</strong><br />
					   Wenbo Nie, <strong>Lang Nie</strong> (Project Lead), Chunyu Lin, Jingwen Chen, Ke Xing, Jiyuan Wang, Kang Liao<br />
					   <a href="https://arxiv.org/abs/2504.00401">[Paper]</a>
					   <a href="https://www.youtube.com/watch?v=C_Vi23kz_gA">[Video]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/RD3D.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Revisiting Monocular 3D Object Detection with Depth Thickness Field</strong><br />
					   Qiude Zhang, Chunyu Lin, Zhijie Shen, <strong>Lang Nie</strong>, Yao Zhao<br />
					   <a href="https://arxiv.org/abs/2412.19165">[Paper]</a>
					   <a href="https://github.com/QiuDeZhang/RD3D">[Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/StableMotion.jpg" width="240" height="130">
				</div>
			<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>StableMotion: Repurposing Diffusion-Based Image Priors for Motion Estimation</strong><br />
					   Ziyi Wang, Haipeng Li, Lin Sui, Tianhao Zhou, Hai Jiang, <strong>Lang Nie</strong>, Shuaicheng Liu<br />
					   <a href="https://arxiv.org/abs/2505.06668">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
<h4>
	<a name='2025'></a> <b>2025</b>
</h4>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/stabstitch2.gif" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps</strong><br />
					   <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Yun Zhang, Shuaicheng Liu, Yao Zhao<br />
					IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)<br />
					   <a href="https://arxiv.org/abs/2505.05001">[Paper]</a>
					   <a href="https://github.com/nie-lang/StabStitch2">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/StabStitch2?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					   <a href="https://www.youtube.com/watch?v=D06ySUVqAXw">[Video]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Jasmine.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation</strong><br />
					   JiYuan Wang, Chunyu Lin, Cheng Guan, <strong>Lang Nie</strong>, Jing He, Haodong Li, Kang Liao, Yao Zhao<br />
						Neural Information Processing Systems Conference (<strong>NeurIPS</strong>)<br />
					   <a href="https://arxiv.org/abs/2503.15905">[Paper]</a>
					   [Code]
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/PixelStitch.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>PixelStitch: Structure-Preserving Pixel-Wise Bidirectional Warps for Unsupervised Image Stitching</strong><br />
					   Hengzhe Jin, <strong>Lang Nie</strong> (Project Lead), Chunyu Lin, Xiaomei Feng, Yao Zhao<br />
					    International Conference on Computer Vision (<strong>ICCV</strong>)<br />
					   [Paper]</a>
					   [Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ConBo-Net.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Lifting the Structural Morphing for Wide-Angle Images Rectification: Unified Content and Boundary Modeling</strong><br />
					   Wenting Luan, Siqi Lu, Yongbin Zheng, Wanying Xu, <strong>Lang Nie</strong>, Zongtan Zhou, Kang Liao<br />
					    International Conference on Computer Vision (<strong>ICCV</strong>)<br />
					   [Paper]</a>
					   [Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TITS25.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Advancing Real-World Parking Slot Detection with Large-Scale Dataset and Semi-Supervised Baseline</strong><br />
						Zhihao Zhang, Chunyu Lin, <strong>Lang Nie</strong>, Jiyuan Wang, Yao Zhao<br />
					   IEEE Transactions on Intelligent Transportation Systems (<strong>TITS</strong>)<br />
						<a href="">[Paper]</a>
						<a href="">[Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Enlter.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>EnIter: Enhancing Iterative Multi-View Depth Estimation with Universal Contextual Hints</strong><br />
					   Qianqian Du, Hui Yin, <strong>Lang Nie</strong>, Yanting Liu, Jin Wang<br />
					   ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>)<br />
						<a href="https://dl.acm.org/doi/pdf/10.1145/3731760">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/SGFormer.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>SGFormer: Spherical Geometry Transformer for 360◦ Depth Estimation</strong><br />
					   Junsong Zhang, Zisong Chen, Chunyu Lin, <strong>Lang Nie</strong>, Zhijie Shen, Yao Zhao<br />
						IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)<br />
					   <a href="https://arxiv.org/abs/2404.14979">[Paper]</a>
					   <a href="https://github.com/iuiuJaon/SGFormer">[Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


<h4>
	<a name='2024'></a> <b>2024</b>
</h4>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/CoupledTPS.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Semi-Supervised Coupled Thin-Plate Spline Model for Rotation Correction and Beyond</strong><br />
					   <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao<br />
					IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)<br />
					   <a href="https://arxiv.org/abs/2401.13432">[Paper]</a>
					   <a href="https://github.com/nie-lang/CoupledTPS">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/CoupledTPS?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/MV-DOPNet.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>360 Layout Estimation via Orthogonal Planes Disentanglement and Multi-view Geometric Consistency Perception</strong><br />
						IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)<br />
					   Zhijie Shen, Chunyu Lin, Junsong Zhang, <strong>Lang Nie</strong>, Kang Liao, Yao Zhao<br />
					   <a href="https://arxiv.org/abs/2312.16268">[Paper]</a>
					   <a href="https://github.com/zhijieshen-bjtu/MV-DOPNet">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhijieshen-bjtu/MV-DOPNet?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/stabstitch.gif" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Eliminating Warping Shakes for Unsupervised Online Video Stitching</strong><br />
					   <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Yun Zhang, Shuaicheng Liu, Rui Ai, Yao Zhao<br />
					European Conference on Computer Vision (<strong>ECCV</strong>)<br />
					   <a href="https://arxiv.org/abs/2403.06378">[Paper]</a>
					   <a href="https://github.com/nie-lang/StabStitch">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/StabStitch?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					   <a href="https://www.youtube.com/watch?v=03kGEZJHxzI">[Video]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/D4RD.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Digging into contrastive learning for robust depth estimation with diffusion models</strong><br />
					   Jiyuan Wang, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Shuwei Shao, Yao Zhao<br />
						ACM Multimedia (<strong>ACM MM</strong>) <br />
					   <a href="https://arxiv.org/abs/2404.09831">[Paper]</a>
					   <a href="https://github.com/wangjiyuan9/D4RD">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/wangjiyuan9/D4RD?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/FDA-YOLO.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Towards Oriented Fisheye Object Detection: Dataset and Baseline</strong><br />
					    Jialin Yang, Chunyu Lin, <strong>Lang Nie</strong>, Zisen Kong, Jiapeng Wang, Yao Zhao<br />
					   ACM Transactions on Multimedia Computing, Communications and Applications (<strong>TOMM</strong>)<br />
					   <a href="https://dl.acm.org/doi/abs/10.1145/3702640">[Paper]</a>
					   <a href="https://github.com/lukanightfever/FishOBB">[Code]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TG-Pose.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>TG-Pose: Delving into Topology and Geometry for Category-level Object Pose Estimation</strong><br />
					   Yue Zhan, Xin Wang, <strong>Lang Nie</strong>, Yang Zhao, Tangwen Yang, Qiuqi Ruan<br />
					   IEEE Transactions on Multimedia (<strong>TMM</strong>)<br />
					   <a href="https://ieeexplore.ieee.org/document/10539316">[Paper]</a>
					   <a href="https://github.com/zhy0321/TG-Pose">[Code]</a>
					   <a href="https://sites.google.com/view/tg-pose/">[Project Page]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/weatherdepth.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth Estimation under Adverse Weather Conditions</strong><br />
					   Jiyuan Wang, Chunyu Lin, <strong>Lang Nie</strong>, Shujun Huang, Yao Zhao, Xing Pan, Rui Ai<br />
					   IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)<br />
					   <a href="https://arxiv.org/abs/2310.05556">[Paper]</a>
					   <a href="https://github.com/wangjiyuan9/WeatherDepth">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/wangjiyuan9/WeatherDepth?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/RecStitchNet.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>RecStitchNet: Learning to Stitch Images with Rectangular Boundaries</strong><br />
					   Yun Zhang, Yu-Kun Lai, <strong>Lang Nie</strong>, Fang-Lue Zhang,  Lin Xu<br />
					   Computational Visual Media Journal (<strong>CVMJ</strong>)<br />
					   <a href="https://link.springer.com/article/10.1007/s41095-024-0420-6">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


<h4>
	<a name='2023'></a> <b>2023</b>
</h4>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/S-OmniMVS.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>S-OmniMVS: Incorporating Sphere Geometry into Omnidirectional Stereo Matching</strong><br />
					   Zisong Chen, Chunyu Lin, <strong>Lang Nie</strong>, Zhijie Shen, Kang Liao, Yuanzhouhan Cao, Yao Zhao<br />
					   ACM Multimedia (<strong>ACM MM</strong>). (<strong><font color="red">Oral presentation</font></strong>)<br />
					   <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3612381">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/UDIS++.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Parallax-Tolerant Unsupervised Deep Image Stitching</strong><br />
					   <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao<br />
					    International Conference on Computer Vision (<strong>ICCV</strong>)<br />
					   <a href="https://arxiv.org/abs/2302.08207">[Paper]</a>
					   <a href="https://github.com/nie-lang/UDIS2">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/UDIS2?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/RecRecNet.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>RecRecNet: Rectangling Rectified Wide-Angle Images by Thin-Plate Spline Model and DoF-based Curriculum Learning</strong><br />
					   Kang Liao*, <strong>Lang Nie*</strong>, Chunyu Lin, Zishuo Zheng, Yao Zhao (* Equal contribution) <br />
					    International Conference on Computer Vision (<strong>ICCV</strong>)<br />
					   <a href="https://arxiv.org/abs/2301.01661">[Paper]</a>
					   <a href="https://github.com/KangLiao929/RecRecNet">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/KangLiao929/RecRecNet?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/GAFlow.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>GAFlow: Incorporating Gaussian Attention into Optical Flow</strong><br />
					   Ao Luo, Fan Yang, Xin Li, <strong>Lang Nie</strong>, Chunyu Lin, Haoqiang Fan, Shuaicheng Liu<br />
					    International Conference on Computer Vision (<strong>ICCV</strong>)<br />
					   <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_GAFlow_Incorporating_Gaussian_Attention_into_Optical_Flow_ICCV_2023_paper.pdf">[Paper]</a>
					   <a href="https://github.com/LA30/GAFlow">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/LA30/GAFlow?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Un-OmniMVS.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Unsupervised OmniMVS: Efficient Omnidirectional Depth Inference via Establishing Pseudo-Stereo Supervision</strong><br />
					   Zisong Chen, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Yao Zhao<br />
					   IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)<br />
					   <a href="https://arxiv.org/abs/2302.09922">[Paper]</a>
					   <a href="https://github.com/Chen-z-s/Un-OmniMVS">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/Chen-z-s/Un-OmniMVS?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/rotation.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Deep Rotation Correction without Angle Prior</strong><br />
					   <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Image Processing (<strong>TIP</strong>)<br />
					   <a href="https://arxiv.org/abs/2207.03054">[Paper]</a>
					   <a href="https://github.com/nie-lang/RotationCorrection">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/RotationCorrection?label=%F0%9F%8C%9F%20Star&color=blue"></a>
						<a href="https://github.com/nie-lang/RotationCorrection">[Dataset]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			
			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/DOP-CVPR23.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Disentangling Orthogonal Planes for Indoor Panoramic Room Layout Estimation with Cross-Scale Distortion Awareness</strong><br />
					   Zhijie Shen, Zishuo Zheng, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Shuai Zheng, Yao Zhao<br />
						IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) <br />
					   <a href="https://arxiv.org/abs/2303.00971">[Paper]</a>
					   <a href="https://github.com/zhijieshen-bjtu/DOPNet">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhijieshen-bjtu/DOPNet?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT23-ADAP.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>As-Deformable-As-Possible Single-image-based View Synthesis without Depth Prior</strong><br />
					   Chunlan Zhang, Chunyu Lin, Kang Liao, <strong>Lang Nie</strong>, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)<br />
					   <a href="https://ieeexplore.ieee.org/abstract/document/10019290">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/pano_seg.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Complementary Bi-directional Feature Compression for Indoor 360° Semantic Segmentation with Self-distillation</strong><br />
					   Zishuo Zheng, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Zhijie Shen, Yao Zhao<br />
					   Winter Conference on Applications of Computer Vision (<strong>WACV</strong>)<br />
					   <a href="https://openaccess.thecvf.com/content/WACV2023/papers/Zheng_Complementary_Bi-Directional_Feature_Compression_for_Indoor_360deg_Semantic_Segmentation_With_WACV_2023_paper.pdf">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


<h4>
	<a name='2022'></a> <b>2022</b>
</h4>
		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/CVPR22-Rectangling.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Deep Rectangling for Image Stitching: A Learning Baseline</strong><br />
					   <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao<br />
					   IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>). (<strong><font color="red">Oral presentation</font></strong>)<br/>
					   <a href="https://arxiv.org/abs/2203.03831">[Paper]</a>
					   <a href="https://github.com/nie-lang/DeepRectangling">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/DeepRectangling?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					   <a href="https://github.com/nie-lang/DeepRectangling">[Dataset]</a>
					   <a href="https://www.youtube.com/watch?v=zx886swXZ2w&t=9s">[Video]</a>
					   <a href="https://zhuanlan.zhihu.com/p/492174095">[Chinese Blog]</a>
						
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/panoformer.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>PanoFormer: Panorama Transformer for Indoor 360° Depth Estimation</strong><br />
					   Zhijie Shen, Chunyu Lin, Kang Liao, <strong>Lang Nie</strong>, Zishuo Zheng, Yao Zhao<br />
					   European Conference on Computer Vision (<strong>ECCV</strong>)<br />
					   <a href="https://arxiv.org/pdf/2203.09283.pdf">[Paper]</a>
					   <a href="https://github.com/zhijieshen-bjtu/PanoFormer">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhijieshen-bjtu/PanoFormer?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/VR22-Sivs.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>SivsFormer: Parallax-Aware Transformers for Single-image-based View Synthesis</strong><br />
					   Chunlan Zhang, Chunyu Lin, Kang Liao, <strong>Lang Nie</strong>, Yao Zhao<br />
					   IEEE Conference on Virtual Reality and 3D User Interfaces (<strong>VR</strong>)<br />
					   <a href="https://ieeexplore.ieee.org/document/9756742">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT22-contourlet.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Neural Contourlet Network for Monocular 360° Depth Estimation</strong><br />
					   Zhijie Shen, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)<br />
					   <a href="https://ieeexplore.ieee.org/document/9833523">[Paper]</a>
					   <a href="https://github.com/zhijieshen-bjtu/Neural-Contourlet-Network-for-MODE">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/zhijieshen-bjtu/Neural-Contourlet-Network-for-MODE?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

<!-- 			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/pano_detection.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Bi-Projection for 360° Image Object Detection Bridged by Roi Searcher</strong><br />
					   Zishuo Zheng, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Yao Zhao<br />
					   Journal of Visual Communication and Image Representation (<strong>JVCIR</strong>)<br />
					   <a href="https://www.sciencedirect.com/science/article/pii/S1047320322001808">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div> -->



<h4>
	<a name='2021'></a> <b>2021</b>
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TIP21-unsupervised.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Unsupervised Deep Image Stitching: Reconstructing Stitched Features to Images</strong><br />
					  <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Image Processing (<strong>TIP</strong>)<br />
					   <a href="https://arxiv.org/abs/2106.12859">[Paper]</a>
					   <a href="https://github.com/nie-lang/UnsupervisedDeepImageStitching">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/UnsupervisedDeepImageStitching?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					   <a href="https://github.com/nie-lang/UnsupervisedDeepImageStitching">[Dataset]</a>
					   <a href="https://zhuanlan.zhihu.com/p/386863945">[Chinese Blog]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT21-homo.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Depth-Aware Multi-Grid Deep Homography Estimation with Contextual Correlation</strong><br />
					  <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)<br />
					   <a href="https://arxiv.org/abs/2107.02524">[Paper]</a>
					   <a href="https://github.com/nie-lang/Multi-Grid-Deep-Homography">[Code]]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/Multi-Grid-Deep-Homography?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Neuro21-stitchnet2.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Learning Edge-Preserved Image Stitching from Multi-Scale Deep Homography</strong><br />
					  <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Yao Zhao<br />
					   Neurocomputing (<strong>NEUCOM</strong>)<br />
					   <a href="https://www.sciencedirect.com/science/article/pii/S0925231221018701?casa_token=ljSQgciO6i8AAAAA:KCCzEx2-_N3GODg9-MsMzoHY-I8r0Zmdf8ksLQGeXEYY9VtfHaxPXzq_kFxuRn6Ap350dZ0vtg">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

<!-- 		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ICME21-dualcube.jpg" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Distortion-Tolerant Monocular Depth Estimation on Omnidirectional Image using Dual-Cubemap</strong><br />
					  Zhijie Shen, Chunyu Lin, <strong>Lang Nie</strong>, Kang Liao, Yao Zhao<br />
					   IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>)<br />
					   <a href="https://arxiv.org/abs/2203.09733">[Paper]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div> -->


<h4>
	<a name='2020'></a> <b>2020</b>
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/JVCIR20-view-free.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>A View-Free Image Stitching Network Based on Global Homography</strong><br />
					  <strong>Lang Nie</strong>, Chunyu Lin, Kang Liao, Meiqin Liu, Yao Zhao<br />
					   Journal of Visual Communication and Image Representation (<strong>JVCIR</strong>)<br />
					   <a href="https://www.sciencedirect.com/science/article/pii/S1047320320301784?casa_token=d1t3NBEDZWQAAAAA:Vn8KVmkW_Bz7RjRD_EmFNzux2KZ4FVUx0wsCIRR88ePqT2jLYp4h9ZTGjByqu_xBEe-O6FYRKw">[Paper]</a>
					   <a href="https://github.com/nie-lang/DeepImageStitching-1.0">[Code]<img style="position: relative; top:4px; height: 18px;" src="https://img.shields.io/github/stars/nie-lang/DeepImageStitching-1.0?label=%F0%9F%8C%9F%20Star&color=blue"></a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


